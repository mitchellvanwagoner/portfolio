Project Description:
To aid in the QA process for my team, I built a custom QA checklist web app using Google Apps Scripts which is built into google sheets. This allowed me to make a clean front end interface for my users, and a simple easy to understand database right in google sheets. My sheet does more than just track errors. It allows the QA'er to get feedback on the success rates for each checklist item broken down by development, city, and designer, giving them the ability to know where problem areas are as they go through a QA. I built two versions of the QA checklist tool and database you see below. Our design team is separated into two divisions, one for “Master” plans, these consist of full community designs, and another for “Individual” designs, which consist of single building plans. Each team is important and are unique from each other, requiring their own set of tools and features. But the broad strokes for each are detailed below.




Image 1:
This is the main QA checklist page, the top half of the page contains the account information pulled directly from our task scheduler. 


Below that, each of the tabs loads in different QA checklist items pertaining to the tab section name. Next to each name are three percentages representing the error rate of that item for either the AHJ, Community, or Designer associated with the current design. 


Image 2:
Each percentage can be clicked on and a dialog box will show all of the previous comments made on that item for that AHJ/Community/Designer. This function of quickly showing the QA’er the problem areas associated with the design they are looking at was my main goal when creating this system. 


Previously we relied on a simple checklist with no real feedback that only generated a QA report for each design. And we got drastically different QA reports from different QA’ers as a result. Each QA’er had their own common issues that they would look at and so our QA process was all over the place. My idea to provide this feedback has greatly helped it getting consistent and accurate QAs from all of our QA’ers.


Image 3:
When each of the items has been reviewed and any comments made, the Review QA button allows the user to click it, opening up the QA Report review popup. When ready the QA’er can copy the text of the report (to paste later on in our process) and then submit the report. When submitted the QA tool will email a copy of the report to the designer as well as their immediate supervisor. It will also publish the QA data to the database.


Image 4 & 5:
I won’t show any specific company info, but in these images you can see how I have the data ingested and analyzed. This image is a breakdown of the designer scores, showing their progress over time and also the QA items they should work on most. Each of the breakdown sheets employs a similar structure with each unique entity having their own error scores over time and their most pressing topic.


The designer scores also track our external teams who we rely on during surge times to provide extra throughput. These scores are built into our contracts with them, making sure they maintain good quality and are not just rushing through designs.


Image 6:
I also generate a graph of the total error scores for each QA item and this gets reviewed every bi-weekly team meeting, giving everyone an idea of what to be mindful of moving forward either as a designer or a QA’er.